{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e0a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76cc94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# I. DATA LOADING AND PREPARATION\n",
    "# =========================================================\n",
    "\n",
    "california_houses=pd.read_csv(\"datasets/California_Houses.csv\")\n",
    "\n",
    "# Separate features (X) and target (T)\n",
    "X = california_houses.drop(columns=['Median_House_Value'])\n",
    "T = california_houses['Median_House_Value']\n",
    "\n",
    "\n",
    "# Shuffle the data to ensure randomness\n",
    "shuffled_data = pd.concat([X, T], axis=1).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "X_shuffled = shuffled_data.drop(columns=['Median_House_Value'])\n",
    "T_shuffled = shuffled_data['Median_House_Value']\n",
    "\n",
    "# Define the split points (70% train, 15% validation, 15% test)\n",
    "#raw means before scaling (normalization)\n",
    "total_rows = X_shuffled.shape[0]\n",
    "train_end = int(total_rows * 0.7)\n",
    "validation_end = int(total_rows * 0.85)\n",
    "\n",
    "# Assign the training data portion (0% to 70%)\n",
    "X_train_raw = X_shuffled.iloc[:train_end]\n",
    "T_train = T_shuffled.iloc[:train_end]\n",
    "\n",
    "# Assign the validation data portion (70% to 85%)\n",
    "X_validation_raw = X_shuffled.iloc[train_end:validation_end]\n",
    "T_validation = T_shuffled.iloc[train_end:validation_end]\n",
    "\n",
    "# Assign the test data portion (85% to 100%)\n",
    "X_test_raw = X_shuffled.iloc[validation_end:]\n",
    "T_test = T_shuffled.iloc[validation_end:]\n",
    "\n",
    "\n",
    "# --- Feature Scaling (Crucial for Gradient Descent) ---\n",
    "\n",
    "#scaler is used to normalize features , mean =0 , std = 1\n",
    "\n",
    "# Gradient Descent converges faster when features are on similar scales\n",
    "# Prevents features with large values from dominating the learning process\n",
    "# Ensures all features contribute equally to the model\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "\n",
    "X_validation_scaled = scaler.transform(X_validation_raw)\n",
    "X_test_scaled = scaler.transform(X_test_raw)\n",
    "\n",
    "\n",
    "# --- Add Bias Term ---\n",
    "\n",
    "# Add bias term (column of ones) to all three scaled sets\n",
    "X_train_with_bias_scaled = np.c_[np.ones((len(X_train_scaled), 1)), X_train_scaled]\n",
    "X_validation_with_bias_scaled = np.c_[np.ones((len(X_validation_scaled), 1)), X_validation_scaled]\n",
    "X_test_with_bias_scaled = np.c_[np.ones((len(X_test_scaled), 1)), X_test_scaled]\n",
    "\n",
    "\n",
    "# --- Reshape Target Vars to col vectors---\n",
    "\n",
    "T_train_col = T_train.values.reshape(-1, 1)\n",
    "T_validation_col = T_validation.values.reshape(-1, 1)\n",
    "T_test_col = T_test.values.reshape(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96208280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "             1. DIRECT SOLUTION (NORMAL EQUATION)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# II. DIRECT SOLUTION (NORMAL EQUATION)\n",
    "# =========================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"             1. DIRECT SOLUTION (NORMAL EQUATION)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# --- 1. Train (Using UN-SCALED features for the Normal Equation) ---\n",
    "\"\"\" \n",
    "The Normal Equation doesn't need normalization(scaled features) because\n",
    "it solves the problem in one step using a closed-form mathematical formula.\n",
    "It's not iterative, so it doesn't suffer from convergence issues.\n",
    "\"\"\"\n",
    "X_train_with_bias_raw = np.c_[np.ones((len(X_train_raw), 1)), X_train_raw.values]\n",
    "\n",
    "# W* = (X_T * X)^-1 * X_T * T\n",
    "W_direct_sol = np.linalg.pinv(X_train_with_bias_raw.T @ X_train_with_bias_raw) @ X_train_with_bias_raw.T @ T_train_col\n",
    "\n",
    "# --- 2. Predict on Test Set ---\n",
    "X_test_with_bias_raw = np.c_[np.ones((len(X_test_raw), 1)), X_test_raw.values]\n",
    "X_validation_with_bias_raw = np.c_[np.ones((len(X_validation_raw), 1)), X_validation_raw.values]\n",
    "\n",
    "T_validation_prediction = X_validation_with_bias_raw @ W_direct_sol\n",
    "T_test_prediction = X_test_with_bias_raw @ W_direct_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285f2806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "             2. GRADIENT DESCENT (BATCH GD)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# III. GRADIENT DESCENT (BATCH GD)\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"             2. GRADIENT DESCENT (BATCH GD)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\"\"\"\n",
    "    Gradient Descent Algorithm for Linear Regression\n",
    "    \n",
    "    Cost Function (MSE):\n",
    "        J(W) = (1/2m) * Σ(i=1 to m) [h(x^(i)) - y^(i)]²\n",
    "        where h(x) = W₀ + W₁x₁ + W₂x₂ + ... + Wₙxₙ = X @ W\n",
    "        my prediction - real thing\n",
    "        \n",
    "    Partial Derivatives (Gradients):\n",
    "        ∂J/∂Wⱼ = (1/m) * Σ(i=1 to m) [(h(x^(i)) - y^(i)) * xⱼ^(i)]\n",
    "        \n",
    "        For each weight Wⱼ (j = 0, 1, 2, ..., n):\n",
    "        - Sum over all m training examples\n",
    "        - Multiply error by the j-th feature value\n",
    "        - Average by dividing by m\n",
    "    \n",
    "    Update Rule:\n",
    "        Wⱼ := Wⱼ - learningRate * ∂J/∂Wⱼ\n",
    "        := means assigned to\n",
    "    \n",
    "    Vectorized Form:\n",
    "        gradient = (1/m) * X^T @ (X @ W - y)\n",
    "    \"\"\"\n",
    "\n",
    "def gradient_descent(X, y, learning_rate=0.01, n_iterations=2000):\n",
    "    m = len(y)\n",
    "    # Initialize theta (coefficients) to zeros\n",
    "    W = np.zeros((X.shape[1], 1))\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        error = (X @ W) - y\n",
    "        gradients = (1/m) * X.T @ error\n",
    "        W = W - learning_rate * gradients\n",
    "\n",
    "    return W\n",
    "\n",
    "# --- 1. Train (Using SCALED features) ---\n",
    "learning_rate = 0.01\n",
    "n_iterations = 2000\n",
    "W_gd = gradient_descent(X_train_with_bias_scaled, T_train_col, learning_rate, n_iterations)\n",
    "\n",
    "# --- 2. Predict on Test Set ---\n",
    "T_validation_predict_gd = X_validation_with_bias_scaled @ W_gd\n",
    "T_test_predict_gd = X_test_with_bias_scaled @ W_gd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f5d9f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IV. GRADIENT DESCENT (BATCH GD) - REGULARIZED VERSIONS\n",
    "\n",
    "\n",
    "# Helper function to calculate Mean Squared Error\n",
    "def calculate_mse(y_true, y_pred):\n",
    "    return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "def ridge_gradient_descent(X, y, lambda_reg, learning_rate=0.01, n_iterations=5000):\n",
    "    m, n = X.shape\n",
    "    # Initialize theta (coefficients)\n",
    "    theta = np.zeros((n, 1))\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        predictions = X @ theta\n",
    "        error = predictions - y\n",
    "        \n",
    "        # Standard Gradient (1/m * X.T @ error)\n",
    "        gradients = (1/m) * X.T @ error\n",
    "\n",
    "        # L2 Regularization Penalty Gradient (2*lambda*w)\n",
    "        # We create a penalty vector: weights * 2 * lambda_reg\n",
    "        # Note: Do NOT penalize the intercept/bias term (index 0)\n",
    "        l2_penalty_gradient = (2 * lambda_reg / m) * theta\n",
    "        l2_penalty_gradient[0] = 0 # Set penalty for bias term to zero\n",
    "\n",
    "        # Update theta with the combined gradient\n",
    "        theta = theta - learning_rate * (gradients + l2_penalty_gradient)\n",
    "        \n",
    "    return theta\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea792b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso regression\n",
    "def lasso_gradient_descent(X, y, lambda_reg, learning_rate=0.01, n_iterations=5000):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n, 1))\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        predictions = X @ theta\n",
    "        error = predictions - y\n",
    "        \n",
    "        # Standard Gradient (1/m * X.T @ error)\n",
    "        gradients = (1/m) * X.T @ error\n",
    "\n",
    "        # L1 Regularization Penalty Gradient (lambda * sign(w))\n",
    "        # We create a penalty vector: lambda * sign(weights)\n",
    "        # Note: Do NOT penalize the intercept/bias term (index 0)\n",
    "        l1_penalty_gradient = (lambda_reg / m) * np.sign(theta)\n",
    "        l1_penalty_gradient[0] = 0 # Set penalty for bias term to zero\n",
    "        \n",
    "        # Update theta with the combined gradient\n",
    "        theta = theta - learning_rate * (gradients + l1_penalty_gradient)\n",
    "        \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1266ded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "           COEFFICIENT COMPARISON\n",
      "============================================================\n",
      "Note: Normal Eq. weights apply to raw features, GD weights to scaled features.\n",
      "\n",
      "                 Feature  Normal Eq. (Raw Scale)   GD (Scaled)\n",
      "               Intercept             -286.853401 207183.649091\n",
      "           Median_Income            38717.982131  71292.629582\n",
      "              Median_Age              850.470609  12229.977163\n",
      "               Tot_Rooms               -4.548680  -1164.666653\n",
      "            Tot_Bedrooms               85.658054  29732.769111\n",
      "              Population              -45.339914 -47282.561159\n",
      "              Households               73.571900  22880.669803\n",
      "                Latitude           -57687.638954 -15007.133608\n",
      "               Longitude           -16526.166308 -28845.676784\n",
      "       Distance_to_coast               -0.275192 -24941.166486\n",
      "          Distance_to_LA               -0.166111 -26355.558470\n",
      "    Distance_to_SanDiego                0.413439   -990.014038\n",
      "     Distance_to_SanJose                0.152918  -4728.549749\n",
      "Distance_to_SanFrancisco               -0.144267  -5768.584498\n",
      "\n",
      "============================================================\n",
      "         TEST SET METRICS COMPARISON\n",
      "============================================================\n",
      "\n",
      "--- Model Performance Comparison on the Test Set ---\n",
      "  Metric Normal Equation Gradient Descent\n",
      "    RMSE       71,689.73        71,774.66\n",
      "R² Score          0.6233           0.6224\n",
      "\n",
      "============================================================\n",
      "           FINAL COEFFICIENTS TABLE\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Normal Eq. (Raw Scale)</th>\n",
       "      <th>GD (Scaled)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-286.853401</td>\n",
       "      <td>207183.649091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Median_Income</td>\n",
       "      <td>38717.982131</td>\n",
       "      <td>71292.629582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Median_Age</td>\n",
       "      <td>850.470609</td>\n",
       "      <td>12229.977163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tot_Rooms</td>\n",
       "      <td>-4.548680</td>\n",
       "      <td>-1164.666653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tot_Bedrooms</td>\n",
       "      <td>85.658054</td>\n",
       "      <td>29732.769111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Population</td>\n",
       "      <td>-45.339914</td>\n",
       "      <td>-47282.561159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Households</td>\n",
       "      <td>73.571900</td>\n",
       "      <td>22880.669803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>-57687.638954</td>\n",
       "      <td>-15007.133608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>-16526.166308</td>\n",
       "      <td>-28845.676784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Distance_to_coast</td>\n",
       "      <td>-0.275192</td>\n",
       "      <td>-24941.166486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Distance_to_LA</td>\n",
       "      <td>-0.166111</td>\n",
       "      <td>-26355.558470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Distance_to_SanDiego</td>\n",
       "      <td>0.413439</td>\n",
       "      <td>-990.014038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Distance_to_SanJose</td>\n",
       "      <td>0.152918</td>\n",
       "      <td>-4728.549749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Distance_to_SanFrancisco</td>\n",
       "      <td>-0.144267</td>\n",
       "      <td>-5768.584498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature  Normal Eq. (Raw Scale)    GD (Scaled)\n",
       "0                  Intercept             -286.853401  207183.649091\n",
       "1              Median_Income            38717.982131   71292.629582\n",
       "2                 Median_Age              850.470609   12229.977163\n",
       "3                  Tot_Rooms               -4.548680   -1164.666653\n",
       "4               Tot_Bedrooms               85.658054   29732.769111\n",
       "5                 Population              -45.339914  -47282.561159\n",
       "6                 Households               73.571900   22880.669803\n",
       "7                   Latitude           -57687.638954  -15007.133608\n",
       "8                  Longitude           -16526.166308  -28845.676784\n",
       "9          Distance_to_coast               -0.275192  -24941.166486\n",
       "10            Distance_to_LA               -0.166111  -26355.558470\n",
       "11      Distance_to_SanDiego                0.413439    -990.014038\n",
       "12       Distance_to_SanJose                0.152918   -4728.549749\n",
       "13  Distance_to_SanFrancisco               -0.144267   -5768.584498"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# V. COMPARISON AND EVALUATION Using SciKit\n",
    "# =========================================================\n",
    "\n",
    "def compare_metrics(T_true, T_pred_normal, T_pred_gd, model_type):\n",
    "    \"\"\"Calculates and compares metrics for both models on a given set.\"\"\"\n",
    "    mse_normal = mean_squared_error(T_true, T_pred_normal)\n",
    "    rmse_normal = np.sqrt(mse_normal)\n",
    "    r2_normal = r2_score(T_true, T_pred_normal)\n",
    "    \n",
    "    mse_gd = mean_squared_error(T_true, T_pred_gd)\n",
    "    rmse_gd = np.sqrt(mse_gd)\n",
    "    r2_gd = r2_score(T_true, T_pred_gd)\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['RMSE', 'R² Score'],\n",
    "        'Normal Equation': [f'{rmse_normal:,.2f}', f'{r2_normal:.4f}'],\n",
    "        'Gradient Descent': [f'{rmse_gd:,.2f}', f'{r2_gd:.4f}']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n--- Model Performance Comparison on the {model_type} ---\")\n",
    "    print(metrics_df.to_string(index=False))\n",
    "    return metrics_df\n",
    "\n",
    "def compare_metrics_all(T_true, T_pred_normal, T_pred_gd, T_pred_sklearn, model_type):\n",
    "    \"\"\"Calculates and compares metrics for all three models on a given set.\"\"\"\n",
    "    mse_normal = mean_squared_error(T_true, T_pred_normal)\n",
    "    rmse_normal = np.sqrt(mse_normal)\n",
    "    r2_normal = r2_score(T_true, T_pred_normal)\n",
    "    \n",
    "    mse_gd = mean_squared_error(T_true, T_pred_gd)\n",
    "    rmse_gd = np.sqrt(mse_gd)\n",
    "    r2_gd = r2_score(T_true, T_pred_gd)\n",
    "    \n",
    "    mse_sklearn = mean_squared_error(T_true, T_pred_sklearn)\n",
    "    rmse_sklearn = np.sqrt(mse_sklearn)\n",
    "    r2_sklearn = r2_score(T_true, T_pred_sklearn)\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['RMSE', 'R² Score'],\n",
    "        'Normal Equation': [f'{rmse_normal:,.2f}', f'{r2_normal:.4f}'],\n",
    "        'Manual GD': [f'{rmse_gd:,.2f}', f'{r2_gd:.4f}'],\n",
    "        'Scikit-Learn SGD': [f'{rmse_sklearn:,.2f}', f'{r2_sklearn:.4f}']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n--- Model Performance Comparison on the {model_type} ---\")\n",
    "    print(metrics_df.to_string(index=False))\n",
    "    return metrics_df\n",
    "\n",
    "# --- 1. Compare Coefficients ---\n",
    "feature_names = ['Intercept'] + list(X_train_raw.columns)\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Normal Eq. (Raw Scale)': W_direct_sol.flatten(),\n",
    "    'GD (Scaled)': W_gd.flatten()\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"           COEFFICIENT COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(\"Note: Normal Eq. weights apply to raw features, GD weights to scaled features.\")\n",
    "print(\"\\n\" + coefficients_df.to_string(index=False))\n",
    "\n",
    "\n",
    "# --- 2. Compare Metrics on Test Set ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"         TEST SET METRICS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "com = compare_metrics(T_test_col, T_test_prediction, T_test_predict_gd, \"Test Set\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"           FINAL COEFFICIENTS TABLE\")\n",
    "print(\"=\"*60)\n",
    "display(coefficients_df)  # or just: coefficients_df (for Jupyter display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d778c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  REGULARIZATION TUNING (Ridge and Lasso)\n",
      "============================================================\n",
      "Optimal Lambda for Ridge: 1.0000e-04 (Min Validation MSE: 4,628,477,244.35)\n",
      "Optimal Lambda for Lasso: 1.0000e-04 (Min Validation MSE: 4,628,477,235.93)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =========================================================\n",
    "# VI. REGULARIZATION TUNING & PLOTTING (Manual Implementation)\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  REGULARIZATION TUNING (Ridge and Lasso)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define a range of lambda values on a log scale for tuning\n",
    "lambda_values = np.logspace(-4, 4, 30) # 30 points from 10^-4 to 10^4\n",
    "\n",
    "# Set training parameters\n",
    "# Note: You may need to tune learning_rate or n_iterations if models don't converge\n",
    "learning_rate = 0.01\n",
    "n_iterations = 5000\n",
    "\n",
    "ridge_validation_errors = []\n",
    "lasso_validation_errors = []\n",
    "\n",
    "# --- 1. RIDGE REGRESSION TUNING ---\n",
    "for lambda_val in lambda_values:\n",
    "    # Train the model on the Training Set\n",
    "    ridge_weights = ridge_gradient_descent(\n",
    "        X_train_with_bias_scaled, T_train_col, \n",
    "        lambda_reg=lambda_val,\n",
    "        learning_rate=learning_rate,\n",
    "        n_iterations=n_iterations\n",
    "    )\n",
    "    \n",
    "    # Predict and evaluate on the Validation Set\n",
    "    T_validation_predict_ridge = X_validation_with_bias_scaled @ ridge_weights\n",
    "    mse_val = calculate_mse(T_validation_col, T_validation_predict_ridge)\n",
    "    ridge_validation_errors.append(mse_val)\n",
    "\n",
    "# --- 2. LASSO REGRESSION TUNING ---\n",
    "for lambda_val in lambda_values:\n",
    "    # Train the model on the Training Set\n",
    "    lasso_weights = lasso_gradient_descent(\n",
    "        X_train_with_bias_scaled, T_train_col, \n",
    "        lambda_reg=lambda_val,\n",
    "        learning_rate=learning_rate,\n",
    "        n_iterations=n_iterations\n",
    "    )\n",
    "    \n",
    "    # Predict and evaluate on the Validation Set\n",
    "    T_validation_predict_lasso = X_validation_with_bias_scaled @ lasso_weights\n",
    "    mse_val = calculate_mse(T_validation_col, T_validation_predict_lasso)\n",
    "    lasso_validation_errors.append(mse_val)\n",
    "\n",
    "# Find optimal lambda\n",
    "optimal_lambda_ridge = lambda_values[np.argmin(ridge_validation_errors)]\n",
    "optimal_lambda_lasso = lambda_values[np.argmin(lasso_validation_errors)]\n",
    "\n",
    "print(f\"Optimal Lambda for Ridge: {optimal_lambda_ridge:.4e} (Min Validation MSE: {np.min(ridge_validation_errors):,.2f})\")\n",
    "print(f\"Optimal Lambda for Lasso: {optimal_lambda_lasso:.4e} (Min Validation MSE: {np.min(lasso_validation_errors):,.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38a4cdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "       3. GRADIENT DESCENT (SCIKIT-LEARN SGDRegressor)\n",
      "============================================================\n",
      "\n",
      "Training completed in 10 iterations\n",
      "\n",
      "Scikit-Learn SGD predictions completed.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# V-B. GRADIENT DESCENT USING SCIKIT-LEARN\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"       3. GRADIENT DESCENT (SCIKIT-LEARN SGDRegressor)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\"\"\"\n",
    "SGDRegressor uses Stochastic Gradient Descent (SGD) by default,\n",
    "which updates weights after each sample (or mini-batch).\n",
    "We configure it to behave more like Batch GD for fair comparison.\n",
    "\n",
    "Key parameters:\n",
    "- max_iter: maximum number of epochs (passes through dataset)\n",
    "- learning_rate: 'constant' with eta0 to match our learning rate\n",
    "- penalty: None for standard linear regression (no regularization)\n",
    "- tol: tolerance for stopping criterion\n",
    "\"\"\"\n",
    "\n",
    "# Initialize SGDRegressor\n",
    "sgd_regressor = SGDRegressor(\n",
    "    max_iter=2000,           # Match our n_iterations\n",
    "    learning_rate='constant', # Use constant learning rate\n",
    "    eta0=0.01,               # Match our learning_rate\n",
    "    penalty=None,            # No regularization (standard linear regression)\n",
    "    random_state=42,         # For reproducibility\n",
    "    tol=1e-6                 # Stopping tolerance\n",
    ")\n",
    "\n",
    "# Train on scaled training data (without bias term - sklearn adds it automatically)\n",
    "sgd_regressor.fit(X_train_scaled, T_train_col.ravel())\n",
    "\n",
    "# Get coefficients (sklearn handles bias separately)\n",
    "W_sklearn = np.concatenate([[sgd_regressor.intercept_[0]], sgd_regressor.coef_])\n",
    "\n",
    "print(f\"\\nTraining completed in {sgd_regressor.n_iter_} iterations\")\n",
    "\n",
    "# --- Predict on Validation and Test Sets ---\n",
    "T_validation_predict_sklearn = sgd_regressor.predict(X_validation_scaled).reshape(-1, 1)\n",
    "T_test_predict_sklearn = sgd_regressor.predict(X_test_scaled).reshape(-1, 1)\n",
    "\n",
    "print(\"\\nScikit-Learn SGD predictions completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5617aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "           COMPREHENSIVE MODEL COMPARISON\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "           COEFFICIENT COMPARISON - ALL METHODS\n",
      "================================================================================\n",
      "Note: Normal Eq. weights apply to raw features.\n",
      "      Manual GD and Scikit-Learn weights apply to scaled features.\n",
      "\n",
      "                 Feature  Normal Eq. (Raw Scale)  Manual GD (Scaled)  Scikit-Learn SGD (Scaled)\n",
      "               Intercept             -286.853401       207183.649091              212668.021608\n",
      "           Median_Income            38717.982131        71292.629582               79967.466777\n",
      "              Median_Age              850.470609        12229.977163               16572.166193\n",
      "               Tot_Rooms               -4.548680        -1164.666653               -9561.538270\n",
      "            Tot_Bedrooms               85.658054        29732.769111               45210.507365\n",
      "              Population              -45.339914       -47282.561159              -46851.624198\n",
      "              Households               73.571900        22880.669803               27940.166474\n",
      "                Latitude           -57687.638954       -15007.133608              -94701.884182\n",
      "               Longitude           -16526.166308       -28845.676784              -61189.048093\n",
      "       Distance_to_coast               -0.275192       -24941.166486              -10363.212785\n",
      "          Distance_to_LA               -0.166111       -26355.558470              -35772.712996\n",
      "    Distance_to_SanDiego                0.413439         -990.014038               63588.333260\n",
      "     Distance_to_SanJose                0.152918        -4728.549749               34245.392558\n",
      "Distance_to_SanFrancisco               -0.144267        -5768.584498              -29174.141522\n",
      "\n",
      "================================================================================\n",
      "         VALIDATION SET METRICS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "--- Model Performance Comparison on the Validation Set ---\n",
      "  Metric Normal Equation Manual GD Scikit-Learn SGD\n",
      "    RMSE       67,661.86 68,313.62        69,705.36\n",
      "R² Score          0.6503    0.6435           0.6288\n",
      "\n",
      "================================================================================\n",
      "         TEST SET METRICS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "--- Model Performance Comparison on the Test Set ---\n",
      "  Metric Normal Equation Manual GD Scikit-Learn SGD\n",
      "    RMSE       71,689.73 71,774.66        72,340.71\n",
      "R² Score          0.6233    0.6224           0.6164\n",
      "\n",
      "================================================================================\n",
      "           SUMMARY & INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "Coefficient Comparison (Manual GD vs Scikit-Learn SGD):\n",
      "  - Maximum difference: 79694.750574\n",
      "  - Average difference: 22204.108499\n",
      "\n",
      "Key Observations:\n",
      "  - All three methods should produce similar results on scaled data\n",
      "  - Small differences may occur due to:\n",
      "    * Different convergence criteria\n",
      "    * Numerical precision\n",
      "    * Implementation details (batch vs stochastic updates)\n",
      "\n",
      "================================================================================\n",
      "           FINAL COEFFICIENTS TABLE\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Normal Eq. (Raw Scale)</th>\n",
       "      <th>Manual GD (Scaled)</th>\n",
       "      <th>Scikit-Learn SGD (Scaled)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-286.853401</td>\n",
       "      <td>207183.649091</td>\n",
       "      <td>212668.021608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Median_Income</td>\n",
       "      <td>38717.982131</td>\n",
       "      <td>71292.629582</td>\n",
       "      <td>79967.466777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Median_Age</td>\n",
       "      <td>850.470609</td>\n",
       "      <td>12229.977163</td>\n",
       "      <td>16572.166193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tot_Rooms</td>\n",
       "      <td>-4.548680</td>\n",
       "      <td>-1164.666653</td>\n",
       "      <td>-9561.538270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tot_Bedrooms</td>\n",
       "      <td>85.658054</td>\n",
       "      <td>29732.769111</td>\n",
       "      <td>45210.507365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Population</td>\n",
       "      <td>-45.339914</td>\n",
       "      <td>-47282.561159</td>\n",
       "      <td>-46851.624198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Households</td>\n",
       "      <td>73.571900</td>\n",
       "      <td>22880.669803</td>\n",
       "      <td>27940.166474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>-57687.638954</td>\n",
       "      <td>-15007.133608</td>\n",
       "      <td>-94701.884182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>-16526.166308</td>\n",
       "      <td>-28845.676784</td>\n",
       "      <td>-61189.048093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Distance_to_coast</td>\n",
       "      <td>-0.275192</td>\n",
       "      <td>-24941.166486</td>\n",
       "      <td>-10363.212785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Distance_to_LA</td>\n",
       "      <td>-0.166111</td>\n",
       "      <td>-26355.558470</td>\n",
       "      <td>-35772.712996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Distance_to_SanDiego</td>\n",
       "      <td>0.413439</td>\n",
       "      <td>-990.014038</td>\n",
       "      <td>63588.333260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Distance_to_SanJose</td>\n",
       "      <td>0.152918</td>\n",
       "      <td>-4728.549749</td>\n",
       "      <td>34245.392558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Distance_to_SanFrancisco</td>\n",
       "      <td>-0.144267</td>\n",
       "      <td>-5768.584498</td>\n",
       "      <td>-29174.141522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature  Normal Eq. (Raw Scale)  Manual GD (Scaled)  \\\n",
       "0                  Intercept             -286.853401       207183.649091   \n",
       "1              Median_Income            38717.982131        71292.629582   \n",
       "2                 Median_Age              850.470609        12229.977163   \n",
       "3                  Tot_Rooms               -4.548680        -1164.666653   \n",
       "4               Tot_Bedrooms               85.658054        29732.769111   \n",
       "5                 Population              -45.339914       -47282.561159   \n",
       "6                 Households               73.571900        22880.669803   \n",
       "7                   Latitude           -57687.638954       -15007.133608   \n",
       "8                  Longitude           -16526.166308       -28845.676784   \n",
       "9          Distance_to_coast               -0.275192       -24941.166486   \n",
       "10            Distance_to_LA               -0.166111       -26355.558470   \n",
       "11      Distance_to_SanDiego                0.413439         -990.014038   \n",
       "12       Distance_to_SanJose                0.152918        -4728.549749   \n",
       "13  Distance_to_SanFrancisco               -0.144267        -5768.584498   \n",
       "\n",
       "    Scikit-Learn SGD (Scaled)  \n",
       "0               212668.021608  \n",
       "1                79967.466777  \n",
       "2                16572.166193  \n",
       "3                -9561.538270  \n",
       "4                45210.507365  \n",
       "5               -46851.624198  \n",
       "6                27940.166474  \n",
       "7               -94701.884182  \n",
       "8               -61189.048093  \n",
       "9               -10363.212785  \n",
       "10              -35772.712996  \n",
       "11               63588.333260  \n",
       "12               34245.392558  \n",
       "13              -29174.141522  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# V-C. COMPREHENSIVE COMPARISON OF ALL METHODS\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"           COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- 1. Compare Coefficients ---\n",
    "feature_names = ['Intercept'] + list(X_train_raw.columns)\n",
    "coefficients_df_full = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Normal Eq. (Raw Scale)': W_direct_sol.flatten(),\n",
    "    'Manual GD (Scaled)': W_gd.flatten(),\n",
    "    'Scikit-Learn SGD (Scaled)': W_sklearn.flatten()\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"           COEFFICIENT COMPARISON - ALL METHODS\")\n",
    "print(\"=\"*80)\n",
    "print(\"Note: Normal Eq. weights apply to raw features.\")\n",
    "print(\"      Manual GD and Scikit-Learn weights apply to scaled features.\")\n",
    "print(\"\\n\" + coefficients_df_full.to_string(index=False))\n",
    "\n",
    "# --- 2. Compare Metrics on Validation Set ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"         VALIDATION SET METRICS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "validation_metrics = compare_metrics_all(\n",
    "    T_validation_col, \n",
    "    T_validation_prediction, \n",
    "    T_validation_predict_gd, \n",
    "    T_validation_predict_sklearn,\n",
    "    \"Validation Set\"\n",
    ")\n",
    "\n",
    "# --- 3. Compare Metrics on Test Set ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"         TEST SET METRICS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "test_metrics = compare_metrics_all(\n",
    "    T_test_col, \n",
    "    T_test_prediction, \n",
    "    T_test_predict_gd,\n",
    "    T_test_predict_sklearn,\n",
    "    \"Test Set\"\n",
    ")\n",
    "\n",
    "# --- 4. Summary Statistics ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"           SUMMARY & INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate coefficient differences\n",
    "coef_diff_manual_sklearn = np.abs(W_gd.flatten() - W_sklearn.flatten())\n",
    "max_coef_diff = np.max(coef_diff_manual_sklearn)\n",
    "avg_coef_diff = np.mean(coef_diff_manual_sklearn)\n",
    "\n",
    "print(f\"\\nCoefficient Comparison (Manual GD vs Scikit-Learn SGD):\")\n",
    "print(f\"  - Maximum difference: {max_coef_diff:.6f}\")\n",
    "print(f\"  - Average difference: {avg_coef_diff:.6f}\")\n",
    "\n",
    "print(f\"\\nKey Observations:\")\n",
    "print(f\"  - All three methods should produce similar results on scaled data\")\n",
    "print(f\"  - Small differences may occur due to:\")\n",
    "print(f\"    * Different convergence criteria\")\n",
    "print(f\"    * Numerical precision\")\n",
    "print(f\"    * Implementation details (batch vs stochastic updates)\")\n",
    "\n",
    "# Display final table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"           FINAL COEFFICIENTS TABLE\")\n",
    "print(\"=\"*80)\n",
    "display(coefficients_df_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
