{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc94a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 4.58930000e+00, 3.90000000e+01, ...,\n",
       "        7.32571538e+05, 7.00855737e+04, 3.72706993e+04],\n",
       "       [1.00000000e+00, 3.98530000e+00, 2.40000000e+01, ...,\n",
       "        7.69657977e+05, 1.56611953e+05, 1.33968764e+05],\n",
       "       [1.00000000e+00, 2.21670000e+00, 1.80000000e+01, ...,\n",
       "        4.55949596e+05, 2.16156065e+05, 2.84095244e+05],\n",
       "       ...,\n",
       "       [1.00000000e+00, 2.93440000e+00, 3.60000000e+01, ...,\n",
       "        1.84842756e+05, 4.85477346e+05, 5.53467812e+05],\n",
       "       [1.00000000e+00, 5.71920000e+00, 1.50000000e+01, ...,\n",
       "        6.94699029e+05, 2.78245773e+04, 4.67503151e+04],\n",
       "       [1.00000000e+00, 2.57550000e+00, 5.20000000e+01, ...,\n",
       "        7.37236735e+05, 6.70261570e+04, 1.08674196e+03]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# I. DATA LOADING AND PREPARATION\n",
    "# =========================================================\n",
    "# Attempt to load the file, handling potential path/index issues from previous runs\n",
    "try:\n",
    "    # Assuming the structure from the last successful read (Median_House_Value as a column)\n",
    "    california_houses = pd.read_csv(\"datasets/California_Houses.csv\")\n",
    "except FileNotFoundError:\n",
    "    california_houses = pd.read_csv(\"California_Houses.csv\")\n",
    "\n",
    "# Separate features (X) and target (T)\n",
    "X = california_houses.drop(columns=['Median_House_Value'])\n",
    "T = california_houses['Median_House_Value']\n",
    "\n",
    "\n",
    "# Shuffle the data\n",
    "shuffled_data = pd.concat([X, T], axis=1).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "X_shuffled = shuffled_data.drop(columns=['Median_House_Value'])\n",
    "T_shuffled = shuffled_data['Median_House_Value']\n",
    "\n",
    "\n",
    "#Splitting data 70% train\n",
    "total_rows = X_shuffled.shape[0]\n",
    "train_end = int(total_rows * 0.7)\n",
    "validation_end = int(total_rows * 0.85)\n",
    "\n",
    "#assign data portions to train validation and test\n",
    "X_train = X_shuffled.iloc[:train_end]\n",
    "T_train = T_shuffled.iloc[:train_end]\n",
    "\n",
    "X_validation = X_shuffled.iloc[train_end:validation_end]\n",
    "T_validation = T_shuffled.iloc[train_end:validation_end]\n",
    "\n",
    "X_test = X_shuffled.iloc[validation_end:]\n",
    "T_test = T_shuffled.iloc[validation_end:]\n",
    "\n",
    "# normalization\n",
    "X_train = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "X_validation = (X_validation - X_train.min()) / (X_train.max() - X_train.min())\n",
    "X_test = (X_test - X_train.min()) / (X_train.max() - X_train.min())\n",
    "\n",
    "# Add a bias term (column of ones) to the training data\n",
    "X_train_b = np.c_[np.ones((len(X_train), 1)), X_train]\n",
    "\n",
    "# Add a bias term to the validation data\n",
    "X_validation_b = np.c_[np.ones((len(X_validation), 1)), X_validation]\n",
    "\n",
    "# Add a bias term to the test data\n",
    "X_test_b = np.c_[np.ones((len(X_test), 1)), X_test]\n",
    "\n",
    "# Reshape the training target variable into a column vector\n",
    "T_train_col = T_train.values.reshape(-1, 1)\n",
    "\n",
    "# Reshape the validation target variable into a column vector\n",
    "T_validation_col = T_validation.values.reshape(-1, 1)\n",
    "\n",
    "# Reshape the test target variable into a column vector\n",
    "T_test_col = T_test.values.reshape(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "96208280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median_Income</th>\n",
       "      <th>Median_Age</th>\n",
       "      <th>Tot_Rooms</th>\n",
       "      <th>Tot_Bedrooms</th>\n",
       "      <th>Population</th>\n",
       "      <th>Households</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Distance_to_coast</th>\n",
       "      <th>Distance_to_LA</th>\n",
       "      <th>Distance_to_SanDiego</th>\n",
       "      <th>Distance_to_SanJose</th>\n",
       "      <th>Distance_to_SanFrancisco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.539668</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>0.019863</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.567481</td>\n",
       "      <td>0.211155</td>\n",
       "      <td>0.027398</td>\n",
       "      <td>0.546362</td>\n",
       "      <td>0.614340</td>\n",
       "      <td>0.079961</td>\n",
       "      <td>0.023023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.538027</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.180503</td>\n",
       "      <td>0.171477</td>\n",
       "      <td>0.067210</td>\n",
       "      <td>0.186976</td>\n",
       "      <td>0.565356</td>\n",
       "      <td>0.212151</td>\n",
       "      <td>0.030283</td>\n",
       "      <td>0.544152</td>\n",
       "      <td>0.612446</td>\n",
       "      <td>0.077112</td>\n",
       "      <td>0.022614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.466028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037260</td>\n",
       "      <td>0.029330</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>0.210159</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.544477</td>\n",
       "      <td>0.612688</td>\n",
       "      <td>0.076894</td>\n",
       "      <td>0.020323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032352</td>\n",
       "      <td>0.036313</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>0.209163</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>0.545050</td>\n",
       "      <td>0.613164</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.019459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.230776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041330</td>\n",
       "      <td>0.043296</td>\n",
       "      <td>0.015752</td>\n",
       "      <td>0.042427</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>0.209163</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>0.545050</td>\n",
       "      <td>0.613164</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.019459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.243921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023323</td>\n",
       "      <td>0.032899</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.031574</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>0.209163</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>0.545050</td>\n",
       "      <td>0.613164</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.019459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.217873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064423</td>\n",
       "      <td>0.075729</td>\n",
       "      <td>0.030578</td>\n",
       "      <td>0.084361</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.209163</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.544235</td>\n",
       "      <td>0.612457</td>\n",
       "      <td>0.076234</td>\n",
       "      <td>0.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.180694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078895</td>\n",
       "      <td>0.106456</td>\n",
       "      <td>0.032344</td>\n",
       "      <td>0.106233</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.209163</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.544235</td>\n",
       "      <td>0.612457</td>\n",
       "      <td>0.076234</td>\n",
       "      <td>0.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.108998</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.064932</td>\n",
       "      <td>0.103042</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.097681</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.208167</td>\n",
       "      <td>0.018710</td>\n",
       "      <td>0.544810</td>\n",
       "      <td>0.612935</td>\n",
       "      <td>0.076755</td>\n",
       "      <td>0.018035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.220087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090213</td>\n",
       "      <td>0.109559</td>\n",
       "      <td>0.043387</td>\n",
       "      <td>0.117250</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.209163</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.544235</td>\n",
       "      <td>0.612457</td>\n",
       "      <td>0.076234</td>\n",
       "      <td>0.018913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Median_Income  Median_Age  Tot_Rooms  Tot_Bedrooms  Population  Households  \\\n",
       "0       0.539668    0.784314   0.022331      0.019863    0.008941    0.020556   \n",
       "1       0.538027    0.392157   0.180503      0.171477    0.067210    0.186976   \n",
       "2       0.466028    1.000000   0.037260      0.029330    0.013818    0.028943   \n",
       "3       0.354699    1.000000   0.032352      0.036313    0.015555    0.035849   \n",
       "4       0.230776    1.000000   0.041330      0.043296    0.015752    0.042427   \n",
       "5       0.243921    1.000000   0.023323      0.032899    0.011491    0.031574   \n",
       "6       0.217873    1.000000   0.064423      0.075729    0.030578    0.084361   \n",
       "7       0.180694    1.000000   0.078895      0.106456    0.032344    0.106233   \n",
       "8       0.108998    0.803922   0.064932      0.103042    0.033717    0.097681   \n",
       "9       0.220087    1.000000   0.090213      0.109559    0.043387    0.117250   \n",
       "\n",
       "   Latitude  Longitude  Distance_to_coast  Distance_to_LA  \\\n",
       "0  0.567481   0.211155           0.027398        0.546362   \n",
       "1  0.565356   0.212151           0.030283        0.544152   \n",
       "2  0.564293   0.210159           0.024390        0.544477   \n",
       "3  0.564293   0.209163           0.022918        0.545050   \n",
       "4  0.564293   0.209163           0.022918        0.545050   \n",
       "5  0.564293   0.209163           0.022918        0.545050   \n",
       "6  0.563231   0.209163           0.020146        0.544235   \n",
       "7  0.563231   0.209163           0.020146        0.544235   \n",
       "8  0.563231   0.208167           0.018710        0.544810   \n",
       "9  0.563231   0.209163           0.020146        0.544235   \n",
       "\n",
       "   Distance_to_SanDiego  Distance_to_SanJose  Distance_to_SanFrancisco  \n",
       "0              0.614340             0.079961                  0.023023  \n",
       "1              0.612446             0.077112                  0.022614  \n",
       "2              0.612688             0.076894                  0.020323  \n",
       "3              0.613164             0.077396                  0.019459  \n",
       "4              0.613164             0.077396                  0.019459  \n",
       "5              0.613164             0.077396                  0.019459  \n",
       "6              0.612457             0.076234                  0.018913  \n",
       "7              0.612457             0.076234                  0.018913  \n",
       "8              0.612935             0.076755                  0.018035  \n",
       "9              0.612457             0.076234                  0.018913  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    452600.0\n",
       "1    358500.0\n",
       "2    352100.0\n",
       "3    341300.0\n",
       "4    342200.0\n",
       "5    269700.0\n",
       "6    299200.0\n",
       "7    241400.0\n",
       "8    226700.0\n",
       "9    261100.0\n",
       "Name: Median_House_Value, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate features (X) and target (T)\n",
    "X = california_houses.drop(columns=['Median_House_Value'])\n",
    "T = california_houses['Median_House_Value']\n",
    "\n",
    "mean = X.mean()\n",
    "std = X.std()\n",
    "\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "display(X.head(10))\n",
    "display(T.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "285f2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data as a whole not x alone and T alone\n",
    "shuffled_data = pd.concat([X, T], axis=1).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate shuffled X and T\n",
    "X_shuffled = shuffled_data.drop(columns=['Median_House_Value'])\n",
    "T_shuffled = shuffled_data['Median_House_Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28bd9a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data 70% train\n",
    "total_rows = X_shuffled.shape[0]\n",
    "train_end = int(total_rows * 0.7)\n",
    "validation_end = int(total_rows * 0.85)\n",
    "\n",
    "#assign data portions to train validation and test\n",
    "X_train = X_shuffled.iloc[:train_end]\n",
    "T_train = T_shuffled.iloc[:train_end]\n",
    "\n",
    "X_validation = X_shuffled.iloc[train_end:validation_end]\n",
    "T_validation = T_shuffled.iloc[train_end:validation_end]\n",
    "\n",
    "X_test = X_shuffled.iloc[validation_end:]\n",
    "T_test = T_shuffled.iloc[validation_end:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3a6c81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Learned Regression Coefficients (Normal Equation) ---\n",
      "                          Coefficient Value\n",
      "Intercept                      2.751753e+05\n",
      "Median_Income                  5.610514e+05\n",
      "Median_Age                     4.350051e+04\n",
      "Tot_Rooms                     -1.780353e+05\n",
      "Tot_Bedrooms                   5.934739e+05\n",
      "Population                    -1.604342e+06\n",
      "Households                     3.983280e+05\n",
      "Latitude                      -4.223777e+05\n",
      "Longitude                     -2.894427e+05\n",
      "Distance_to_coast             -7.705033e+04\n",
      "Distance_to_LA                -1.522214e+05\n",
      "Distance_to_SanDiego           2.827004e+05\n",
      "Distance_to_SanJose            1.232811e+05\n",
      "Distance_to_SanFrancisco      -1.114679e+05\n"
     ]
    }
   ],
   "source": [
    "#apply direct sol\n",
    "\n",
    "# The design matrix X_Design_Matrix includes a column of ones for the bias term \n",
    "X_Design_Matrix = np.c_[np.ones((len(X_train), 1)), X_train.values]\n",
    "\n",
    "# Convert T_train to a numpy arr\n",
    "T_Column_Vector = T_train.values.reshape(-1, 1)\n",
    "\n",
    "# 3. Apply Normal Equation: w* = (X_T * X)^-1 * X_T * T\n",
    "# Calculate the optimal weight vector w* using the Normal Equation\n",
    "# Note: np.linalg.pinv is safer for inversion in real-world data than np.linalg.inv\n",
    "W_Star_Column_Vector = np.linalg.pinv(X_Design_Matrix.T @ X_Design_Matrix) @ X_Design_Matrix.T @ T_Column_Vector\n",
    "\n",
    "# Create a DataFrame to display the coefficients\n",
    "feature_names = ['Intercept'] + list(X_train.columns)\n",
    "coefficients_df = pd.DataFrame(W_Star_Column_Vector, index=feature_names, columns=['Coefficient Value'])\n",
    "\n",
    "print(\"\\n--- Learned Regression Coefficients (Normal Equation) ---\")\n",
    "print(coefficients_df)\n",
    "\n",
    "# Prediction on the training set\n",
    "X_train_b = np.c_[np.ones((len(X_train), 1)), X_train.values]\n",
    "T_train_predict = X_train_b @ W_Star_Column_Vector \n",
    "# print(\"\\nFirst 5 Predicted House Values on Training Set:\", T_train_predict[:5].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98c77328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 4573978531.2095\n",
      "Validation R²: 0.6506\n"
     ]
    }
   ],
   "source": [
    "# Prepare validation data\n",
    "X_validation_b = np.c_[np.ones((len(X_validation), 1)), X_validation.values]\n",
    "\n",
    "X_validation_b = (X_validation_b - X_validation_b.min()) / (X_validation_b.max() - X_validation_b.min())\n",
    "# Predict on validation set\n",
    "T_validation_predict = X_validation_b @ W_Star_Column_Vector\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(T_validation, T_validation_predict)\n",
    "r2 = r2_score(T_validation, T_validation_predict)\n",
    "\n",
    "print(f\"Validation MSE: {mse:.4f}\")\n",
    "print(f\"Validation R²: {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
